# Specify the levels of factor_survey_vector
levels(factor_survey_vector)
# Code to build factor_survey_vector
survey_vector <- c("M", "F", "F", "M", "M")
factor_survey_vector <- factor(survey_vector)
# Specify the levels of factor_survey_vector
levels(factor_survey_vector)
cbind(1,2)
cbind(1,2,3,4)
c(1,2,3,4)
levels(factor_survey_vector) <- c("Female", "Male")
levels(factor_survey_vector)
levels(factor_survey_vector) <- cbind("Female", "Male")
cbind()
levels(factor_survey_vector) <- cbind("Female", "Male")
levels(factor_survey_vector)
summart(factor_survey_vector)
summary(factor_survey_vector)
str(factor_survey_vector)
?data.frame()
?data.frame(c(1,2,3,4,5),c(2,3,4,5,6))
data.frame(c(1,2,3,4,5),c(2,3,4,5,6))
data.frame(c(1,2,3,4,5),c(2,3,4,5,6), col.names=1:2)
data.frame(c(1,2,3,4,5),c(2,3,4,5,6), col.names=c(1,2)
)
data.frame(c(1,2,3,4,5),c(2,3,4,5,6), col.names=c('1','2'))
data.frame(a=c(1,2,3,4,5),b=c(2,3,4,5,6))
df = data.frame(a=c(1,2,3,4,5),b=c(2,3,4,5,6))
df
df$a
df[1]
df[1,:]
df[1,]
df[1,2]
df[1,'b']
df[,'b']
df['b']
type(df['b'])
class(df['b'])
class(df[,'b'])
df
df[2,]
class(df[2,])
class(as.numeric(df[2,])
)
class(as.numeric(df[2,]))
as.numeric(df[2,])
class(as.numeric(df[,1]))
class(as.numeric(df[1]))
class(as.numeric(df['1']))
class(as.numeric(df[1]))
class(df[1])
df[1]
as.numercic(df[1])
as.numereric(df[1])
as.numeric(df[1])
as.numeric(df[1])
df$a
mylist = list(a=c(1,2,3),b='hola',c=data.frame(a=c(1,2,3,4,5),b=c(2,3,4,5,6)))
mylist
mylist[1]
mylist[2]
mylist[3]
mylist[[2]]
mylist[2]
type(mylist[2])
class(mylist[2])
class(mylist[[2]])
a = c(4,5,6,7)
a
as.numeric(c(2,"45","1bc","TRUE")) #as.logical, as.character
1:10 < 5
as.numeric(c(TRUE, FALSE))
a[c(2,3)]
a[a]
a[c(TRUE,FALSE,FALSE,FALSE)]
4:1
4:1 * 4:1
quantile(0:20, 0.5)
class(quantile(0:20, 0.5))
str_detect(c("cat","rat","dog"),"at")
library(stringr)
str_detect(c("cat","rat","dog"),"at")
var1 = c('a','b','a','c','d
_)
)
0)))
exit
bye
var1 = c('a','b','a','c','d')
var1 = c('a','b','a','c','d')
fac.var1 =  factor(var1)
var1
fac.var1
summary(fac.var1)
a = cut(1:4, c(0,2,4,8))
a
poker_vector <- c(140, -50, 20, -120, 240)
pv <- c(140, -50, 20, -120, 240)
pv
names(pv)
days_vector <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")
names(pv) <- days_vector
names(pv)
pv
region <- c("US", "non-US")
titles <- c("A New Hope", "The Empire Strikes Back", "Return of the Jedi")
colnames(star_wars_matrix) <- region
urvey_vector <- c("M", "F", "F", "M", "M")
factor_survey_vector <- factor(survey_vector)
# Specify the levels of factor_survey_vector
levels(factor_survey_vector)
cbind("Female", "Male")
c("Female", "Male")
a = cbind("Female", "Male")
a
b = rbind("Female", "Male")
b
m = matrix(1:9, byrow= TRUE, nrow=3)
m
rbind(m, c(7, 7, 7))
cbind(m, c(7, 7, 7))
cbind(7,7,7)
a
a = cbind(7,8,9)
b = rbind(7,8,9)
a
a[2]
a[1,2]
a[2,1]
a[1,1]
b[2,1]
b
vec =c('x','y','z','a','b','c')vec[c(-4, -2)]
vec =c('x','y','z','a','b','c')
vec[c(-4, -2)]
c(-4, -2)
vec[c(-1]
vec[c(-1])
vec[-1)
vec[-1]
vec
vec[-2]
vec[-1]
vec[-3]
vec[-2]
vec[-4]
vec[-3]
vec
vec[-1]
vec[-2]
vec[-2,-3]
vec[c(-2,-3)]
vec =c('x','y','z','a','b','c')
vec =c('x','y','z','a','b','c')
vec =c('x','y','z','a','b','c')
vec[c(6,3,3,1)]
vec =c(-1,2,1)
sum(vec)
sum(vec) != vec
og =c(FALSE, TRUE, FALSE, TRUE
)
og
og[!og]
vec =c(4,2,1,3)
vec[vec]
a =list(5:3,c(2,4),rep(c(1,2),3))
a[2]
a[[2]]
class(a[2])
class(a[[2]])
class(a[[4]])
class(a[4])
a[4]
a
a =list(5:3,c(2,4),rep(c(1,2),3),6)
a[4]
a[[4]]
class(a[[4]])
a =list(0:1, 1:4,c(50,50))
lapply(a,sum)
a =list(0:1, 1:4,c(50,50))
lapply(a, function(x) {length(x)*2 }
)
df =data.frame(a=1:3, b=4:6, c=7:9)
apply(X=df, MARGIN=1, max)
apply(X=df, max)
?apply
c(1,3,5,7) %in%c(1,5,9)
c(1,5,9) %in%c(1,3,5,7)
df =data.frame(x=15:11,y=21:25)
df
arrange(df, x)
library(dplyr)
arrange(df, x)
mutate(df, z=x+y)
filter(df, x>12, y>22)
df =data.frame(x=4:9, y=c(1,1,1,2,2,3))
df
df %>%group_by(y) %>%summarize(cnt =n(),avg =mean(x))
df %>%group_by(y) %>%arrange(x)
df %>%group_by(y) %>% arrange(x)
df
df =data.frame(x=c(33,10,222,100,66,5), y=c(1,2,1,1,2,2))
df %>%group_by(y) %>% arrange(x)
df
df %>%group_by(y) %>%slice()
df
linkedin <- list(16, 9, 13, 5, 2, 17, 14)
facebook <- list(17, 7, 5, 16, 8, 13, 14)
# Convert linkedin and facebook to a vector: li_vec and fb_vec
li_vec <- as.vector(linkedin)
fb_vec <- as.vector(facebook)
li_vec
as.vector(linkedin)
class(as.vector(linkedin))
class(as.numeric(linkedin))
as.numeric(linkedin)
rep(1, 7, by = 2)
rep(1, 7)
rep(1, 7, by=10)
?rep
seq(1,100)
seq(1,100,2)
seq(1,100,2)??
?
?seq
date()
d <- date()
class(d)
d
date(d)
sys.date()
Sys.Date()
d < -Sys.Date()
d <- Sys.Date()
class(d)
d
hwmjnj=HoltWinters(q.jnj,seasonal='multiplicative')
library()
as.vector(linkedin)
library(FinTS)
data(q.jnj) # load data
class(q.jnj) #
head(q.jnj)
q.jnj
plot(q.jnj)
lines(q.jnj)
lines(q.jnj)
str(q.jnjts)
q.jnjts=as.ts(q.jnj)
class(q.jnjts)
str(q.jnjts)
jnjda=decompose(q.jnjts,type='additive')
#Consider the structure (str) of the object returned by decompose().
str(jnjda)
plot(jnjda$trend)
plot(jnjda$sesonal)
plot(jnjda$random)
plot(jnjda$sesonal)
plot(jnjda$sessonal)
predda=jnjda$trend+jnjda$seasonal
#layout(1:1)
plot(q.jnj,lwd=2)
lines(predda,col='red',lwd=2)
predda=jnjda$trend+jnjda$seasonal+jnjda$random
predda=jnjda$trend+jnjda$seasonal+jnjda$random
#layout(1:1)
plot(q.jnj,lwd=2)
lines(predda,col='red',lwd=2)
layout(1:1)
predda=jnjda$trend+jnjda$seasonal
layout(1:1)
plot(q.jnj,lwd=2)
lines(predda,col='red',lwd=2)
time(jnjda)
time(q.jnjts)
jnjdm=decompose(q.jnjts,type='multiplicative')
# we can plot (same as above) and check root squeare mean error
preddm=jnjdm$trend*jnjdm$seasonal
resid=q.jnjts-preddm
jnjdmresid=window(resid, start=c(1960,3), end=c(1980,2))
rmsedm=sqrt(sum(jnjdmresid^2)/length(jnjdmresid))
rmsedm
jnjd=stl(q.jnj,s.window='periodic')
str(jnjd)
#The object jnjd is a list of 8 items. The one of interest to us is the first item
#This item is a 'matrix' of three columns, 'seasonal','trend','remainder' (or error) component.
#The object jnjd$time.series gives us the three components.
class(jnjd$time.series[,'seasonal'])
plot(jnjd)
pred1=jnjd$time.series[,'seasonal'] + jnjd$time.series[,'trend']
plot(q.jnj,lwd=2)
lines(pred1,col='red',lwd=2)
#rmsed
rmsed=sqrt(sum(jnjd$time.series[,'remainder']^2)/length(jnjd$time.series[,'remainder']))
rmsed
plot(jnjd$time.series[,'remainder'],ylab='Remainder')#plot reminder
# to do multiplicative model
logjnj=log(q.jnj)
plot(logjnj,ylab='log(J&J earnings)')
tsjnjd=stl(logjnj,s.window='periodic')
plot(tsjnjd)
################# REGRESION
#If we want to forecast beyond the last date at which we have data we need to create a forecast of the trend component.
#One approach is to forecast the trend component using a linear regression model
#We want to regress the trend of the log transformed data against time so
#we need to extract the time values of the time series as a separate variable.
tr=tsjnjd$time.series[,'trend']
tim=time(tr)
ti = unclass(tim)
trreg=lm(tr~ti)
plot(tr,lwd=2)
preddata=predict(trreg,data.frame(ti=predtime),se.fit=TRUE)
preddata
predtime=seq(1981,1982, by=.25)
predtime
preddata=predict(trreg,data.frame(ti=predtime),se.fit=TRUE)
preddata
tail(tsjnjd$time.series[,'seasonal'])
season=c(-0.003158759,0.033553454,0.116309601,-0.146704527,-0.003158759)
predvalues=preddata$fit
spredvalues=predvalues+season
spredvalues
# to get 95 confidence intervals
prederror=preddata$se.fit
predupperse=spredvalues+2*prederror
predlwrse=spredvalues-2*prederror
epredvalues=exp(spredvalues)
epredupperse=exp(predupperse)
epredlwrse=exp(predlwrse)
#plot
plot(ti,logjnj,ylim=c(-3,5),xlim=c(1960,1983),type='l')
lines(ti,fitted(trreg),col='red')
points(predtime,predvalues,col='red',pch=19,cex=.8)
lines(predtime,predupperse,col='blue',lwd=2)
lines(predtime,predlwrse,col='blue',lwd=2)
lines(predtime,predlwrse,col='blue',lwd=2)
#plot just the prediction
plot(predtime,spredvalues,ylim=c(2,5),col='red',type='l')
lines(predtime,predupperse,col='blue',lwd=2)
lines(predtime,predlwrse,col='blue',lwd=2)
jtime=time(q.jnj)
jseas=cycle(q.jnj)
jdata=coredata(q.jnj)
jnjreg=lm(jdata~0+jtime+factor(jseas))
summary(jnjreg)
# we understand that the residuals will likely be correlated which technically violates the assumptions
#required for regression (more on that later).
plot(jnjreg)
lines(jtime,jnjhat,col='red')
#hist errors
hist(ejnj)
#AUTOCORRELATION
acf(ejnj)
jnjhat=fitted(jnjreg)
lot(q.jnj,ylim=c(-5,20))
lines(jtime,jnjhat,col='red')
plot(q.jnj,ylim=c(-5,20))
lines(jtime,jnjhat,col='red')
hist(ejnj)
#AUTOCORRELATION
acf(ejnj)
ejnj=resid(jnjreg)
hist(ejnj)
acf(ejnj)
plot(rnomr(100), type='l')
plot(rnorm(100), type='l')
plot(rnorm(100), type='l')
x <- rnorm(100)
r
plot(x)
par("mar")
par(mar=c(1,1,1,1))
plot(x)
lines(x)
help("arima")
help(auto.arima)
??auto.arima
install.packages('shinydashboard')
Acf(dfxts, lag=30)
print("p-value: ",pnorm(m, lower.tail =FALSE)
pnorm(4)
print("fad",pnorm(4))
print("fad" + pnorm(4))
print("fad",int(pnorm(4))
)
print("fad",toString(pnorm(4))
)
cat("fad",toString(pnorm(4))
)
help(arima)
# World Development Indicators
#
# This script loads csv downloaded from ://data.worldbank.org/topic
# makes years as a feature and concatenates them together into one data.frame
# then selects a good combination of years/countries without missing values
# Load the WDI, readr and dplyr libraries
library(WDI)
library(readr)
library(dplyr)
library(tidyr)
# disable scientific notation. Easiear to read
options(scipen=999)
# Read each one fo the indicators into a data frame from the downloaded CSV files (remove manuall first 3 lines of cvs)
setwd("C:/Users/carrai1/Desktop/Master/MA402_Data_Science/Assigment_1/")
pop0.df = read_csv("./data/%_population_0_14_60_15.csv")
pop15.df = read_csv("./data/%_population_15_64_60_15.csv")
poprur.df= read_csv("./data/%_rural_population_60_15.csv")
popur.df= read_csv("./data/%_urban_population_60_15.csv")
co2.df= read_csv("./data/CO2_emisions_60_11.csv")
kmsqr.df= read_csv("./data/km_square_61_15.csv")
popgrowth.df= read_csv("./data/population_growth_60_15.csv")
poptotal.df= read_csv("./data/population_total_60_15.csv")
energy.df= read_csv("./data/energy_use_kg_oil.csv")
gdp_growth.df= read_csv("./data/GDP_growth_annual%.csv")
gdp.df= read_csv("./data/GDP.csv")
# put all data.frames into a list
all.list <- list(pop0.df,pop15.df,poprur.df,popur.df,co2.df,kmsqr.df,
popgrowth.df,poptotal.df,energy.df,gdp_growth.df,gdp.df)
# Join all data.frames into a single data.frame
wdi.df = data.frame()
# loop the list to set year and value as a column and concatenate
for (aux.df in all.list){
# Rename a few variable
aux.df <- rename(aux.df, country.name = `Country Name`, country.code = `Country Code`,indicator.name = `Indicator Name`,indicator.code = `Indicator Code`)
# "Gather" the year variables and values into a pair of variables: `year` and `value`
aux.df <- gather(aux.df, year, value, -country.name, -country.code, -indicator.name, -indicator.code)
#concatenates
wdi.df <- rbind(aux.df,wdi.df)
}
#remove column year=x61 and country.code=INX with 100% missing values
wdi.df <- filter(wdi.df, year!="X61")
wdi.df <- filter(wdi.df, country.code!="INX")
# Make the `indicator.code` variable into a factor
wdi.df$indicator.code = factor(wdi.df$indicator.code)
# Make the `country.code` variable into a factor
wdi.df$country.code = factor(wdi.df$country.code)
# Make the `year` variable into an ordered factor
wdi.df$year = factor(wdi.df$year, ordered=TRUE)
#select 5 countries of interest (https://en.wikipedia.org/wiki/BRICSg) and years 1992/2011 (2 decades/20 years)
wdi.df %>% filter(. , country.code %in% c("BRA","CHN","IND","RUS","ZAF")) -> wdi.df
wdi.df <- filter(wdi.df, year>1991 & year<2012)
# are there missing values for any of our countries?
wdi.df %>%  group_by(country.code) %>%  summarize(count=n(), cnt.missing=sum(is.na(value)), pct.missing= 100*cnt.missing/count) %>%
arrange(country.code) %>%  select(country.code, pct.missing) %>%  arrange(desc(pct.missing)) %>% print(n=250)
# Let's save our final data.frame wdi.dfv2 as a csv file
write.csv(file=("./data/wdi.df.csv"), x=wdi.df)
#Describe each variable, including the units of the numeric varables. Describe the meaning of the observations of the dataset.
#Include summaries of individual variables using only the group_by and summarize functions
#from the dplyr library. You must use the pipe operator from the magrittr library.
#Each summary should be interpreted in a way that informs the reader of important
#information about that variable or those variables in the context of the data set.
# drom extra columns
drops=c('country.name','indicator.name')
wdi.df = wdi.df[ , !(names(wdi.df) %in% drops)]
wdi.df$country.code = factor(wdi.df$country.code) #refactor
wdi.df$year = factor(wdi.df$year, ordered=TRUE) #refactor
wdi.df$indicator.code = factor(wdi.df$indicator.code, ordered=TRUE) #refactor
#column value to numberic
wdi.df$value <- as.numeric(wdi.df$value)
#transform data frame to have a column for each indicator
wdi.df %>% spread(., indicator.code, value) -> wdi.df
#rename indicator columns for better understanding
wdi.df %>% rename(. , surface.km2 =AG.SRF.TOTL.K2,
energy.use = EG.USE.PCAP.KG.OE,
co2.emission = EN.ATM.CO2E.PC,
GDP = NY.GDP.MKTP.CD,
GDP.growth = NY.GDP.MKTP.KD.ZG,
pop.0.14 = SP.POP.0014.TO.ZS,
pop.15.64 = SP.POP.1564.TO.ZS,
pop.growth = SP.POP.GROW,
pop.total =  SP.POP.TOTL,
pop.rural=  SP.RUR.TOTL.ZS,
pop.urban =SP.URB.TOTL.IN.ZS
) -> wdi.df
#create new indicator POPULATION DENSITY = POPULATION TOTAL/TOTAL COUNTRY SURFACE
wdi.df %>% mutate(., pop.density = pop.total / surface.km2) -> wdi.df
wdi.df$surface.km2 <- NULL
#get quartiles. Not sure how we are going to use them but professor wanted us to have it.
#we do it for all indicators and usen the name of the column + .q
make.ntiles = function (inputvar, n) {
inputvar %>%
quantile(.,
(1/n) * 1:(n-1),
na.rm=TRUE
) %>%
c(-Inf, ., Inf) %>%
cut(inputvar,
breaks=.,
paste("Q", 1:n, sep="")
)
}
wdi.df %>%  mutate(energy.use.q = make.ntiles(energy.use, 4 ),
co2.emission.q = make.ntiles(co2.emission, 4 ),
GDP.q = make.ntiles(GDP, 4 ),
GDP.growth.q = make.ntiles(GDP.growth, 4 ),
pop.0.14.q = make.ntiles(pop.0.14, 4 ),
pop.15.64.q = make.ntiles(pop.15.64, 4 ),
pop.growth.q = make.ntiles(pop.growth, 4 ),
pop.total.q =  make.ntiles(pop.total, 4 ),
pop.rural.q =  make.ntiles(pop.rural, 4 ),
pop.urban.q = make.ntiles(pop.urban, 4 ),
pop.density.q = make.ntiles(pop.density, 4)
) -> wdi.df
# now we can work on the summaries...
indicators <- c("energy.use", "co2.emission","GDP", "GDP.growth", "pop.0.14", "pop.15.64",
"pop.growth", "pop.total", "pop.rural", "pop.urban", "pop.density")
#summaries of all the indicators during the 2 decades
summary(wdi.df[indicators])
wdi.df %>% group_by(country.code) %>% summarise(avg=mean(energy.use), median=median(energy.use), sd=sd(energy.use), max=max(energy.use),min=min(energy.use)) %>% print("energy.use",.)
wdi.df %>% group_by(country.code) %>% summarise(avg=mean(energy.use), median=median(energy.use), sd=sd(energy.use), max=max(energy.use),min=min(energy.use)) %>% print(.)
