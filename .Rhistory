var1 = c('a','b','a','c','d')
fac.var1 =  factor(var1)
fac.var1
summary(fac.var1)
cut(1:10, c(-Inf, 3, 6, Inf))
help(cut)
a = cut(1:4,c(0,10,20,30,40))
a
a = cut(1:10,c(0,10,20,30,40))
a
a = cut(0:10,c(0,10,20,30,40))
a
a = cut(1:40,c(0,10,20,30,40))
a
cut(1:10, c(2, 4))
cut(1:4, c(2, 4,8))
cut(1:4, c(0,2,4,8))
c("a","b","c")         %>% str_detect(c("cat"), .)
c("cat", "rat", "dog") %>% str_detect(.       , c("a"))
c("cat", "rat", "dog") %>% str_detect("a")
c("cat", "rat", "dog") %>% {print(.); str_detect(., "a")}
3 %>% {print(.); sum(., .)}
cut(1:4, c(0,2,4,8))
a = cut(1:4, c(0,2,4,8))
a
a[2]
a[2] * 3
a[2] + 3
a[2][2]
a[2][1]
a[2][0]
level(a)
levels(a)
# Code to build factor_survey_vector
survey_vector <- c("M", "F", "F", "M", "M")
factor_survey_vector <- factor(survey_vector)
# Specify the levels of factor_survey_vector
levels(factor_survey_vector)
# Code to build factor_survey_vector
survey_vector <- c("M", "F", "F", "M", "M")
factor_survey_vector <- factor(survey_vector)
# Specify the levels of factor_survey_vector
levels(factor_survey_vector)
cbind(1,2)
cbind(1,2,3,4)
c(1,2,3,4)
levels(factor_survey_vector) <- c("Female", "Male")
levels(factor_survey_vector)
levels(factor_survey_vector) <- cbind("Female", "Male")
cbind()
levels(factor_survey_vector) <- cbind("Female", "Male")
levels(factor_survey_vector)
summart(factor_survey_vector)
summary(factor_survey_vector)
str(factor_survey_vector)
?data.frame()
?data.frame(c(1,2,3,4,5),c(2,3,4,5,6))
data.frame(c(1,2,3,4,5),c(2,3,4,5,6))
data.frame(c(1,2,3,4,5),c(2,3,4,5,6), col.names=1:2)
data.frame(c(1,2,3,4,5),c(2,3,4,5,6), col.names=c(1,2)
)
data.frame(c(1,2,3,4,5),c(2,3,4,5,6), col.names=c('1','2'))
data.frame(a=c(1,2,3,4,5),b=c(2,3,4,5,6))
df = data.frame(a=c(1,2,3,4,5),b=c(2,3,4,5,6))
df
df$a
df[1]
df[1,:]
df[1,]
df[1,2]
df[1,'b']
df[,'b']
df['b']
type(df['b'])
class(df['b'])
class(df[,'b'])
df
df[2,]
class(df[2,])
class(as.numeric(df[2,])
)
class(as.numeric(df[2,]))
as.numeric(df[2,])
class(as.numeric(df[,1]))
class(as.numeric(df[1]))
class(as.numeric(df['1']))
class(as.numeric(df[1]))
class(df[1])
df[1]
as.numercic(df[1])
as.numereric(df[1])
as.numeric(df[1])
as.numeric(df[1])
df$a
mylist = list(a=c(1,2,3),b='hola',c=data.frame(a=c(1,2,3,4,5),b=c(2,3,4,5,6)))
mylist
mylist[1]
mylist[2]
mylist[3]
mylist[[2]]
mylist[2]
type(mylist[2])
class(mylist[2])
class(mylist[[2]])
a = c(4,5,6,7)
a
as.numeric(c(2,"45","1bc","TRUE")) #as.logical, as.character
1:10 < 5
as.numeric(c(TRUE, FALSE))
a[c(2,3)]
a[a]
a[c(TRUE,FALSE,FALSE,FALSE)]
4:1
4:1 * 4:1
quantile(0:20, 0.5)
class(quantile(0:20, 0.5))
str_detect(c("cat","rat","dog"),"at")
library(stringr)
str_detect(c("cat","rat","dog"),"at")
var1 = c('a','b','a','c','d
_)
)
0)))
exit
bye
var1 = c('a','b','a','c','d')
var1 = c('a','b','a','c','d')
fac.var1 =  factor(var1)
var1
fac.var1
summary(fac.var1)
a = cut(1:4, c(0,2,4,8))
a
poker_vector <- c(140, -50, 20, -120, 240)
pv <- c(140, -50, 20, -120, 240)
pv
names(pv)
days_vector <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")
names(pv) <- days_vector
names(pv)
pv
region <- c("US", "non-US")
titles <- c("A New Hope", "The Empire Strikes Back", "Return of the Jedi")
colnames(star_wars_matrix) <- region
urvey_vector <- c("M", "F", "F", "M", "M")
factor_survey_vector <- factor(survey_vector)
# Specify the levels of factor_survey_vector
levels(factor_survey_vector)
cbind("Female", "Male")
c("Female", "Male")
a = cbind("Female", "Male")
a
b = rbind("Female", "Male")
b
m = matrix(1:9, byrow= TRUE, nrow=3)
m
rbind(m, c(7, 7, 7))
cbind(m, c(7, 7, 7))
cbind(7,7,7)
a
a = cbind(7,8,9)
b = rbind(7,8,9)
a
a[2]
a[1,2]
a[2,1]
a[1,1]
b[2,1]
b
vec =c('x','y','z','a','b','c')vec[c(-4, -2)]
vec =c('x','y','z','a','b','c')
vec[c(-4, -2)]
c(-4, -2)
vec[c(-1]
vec[c(-1])
vec[-1)
vec[-1]
vec
vec[-2]
vec[-1]
vec[-3]
vec[-2]
vec[-4]
vec[-3]
vec
vec[-1]
vec[-2]
vec[-2,-3]
vec[c(-2,-3)]
vec =c('x','y','z','a','b','c')
vec =c('x','y','z','a','b','c')
vec =c('x','y','z','a','b','c')
vec[c(6,3,3,1)]
vec =c(-1,2,1)
sum(vec)
sum(vec) != vec
og =c(FALSE, TRUE, FALSE, TRUE
)
og
og[!og]
vec =c(4,2,1,3)
vec[vec]
a =list(5:3,c(2,4),rep(c(1,2),3))
a[2]
a[[2]]
class(a[2])
class(a[[2]])
class(a[[4]])
class(a[4])
a[4]
a
a =list(5:3,c(2,4),rep(c(1,2),3),6)
a[4]
a[[4]]
class(a[[4]])
a =list(0:1, 1:4,c(50,50))
lapply(a,sum)
a =list(0:1, 1:4,c(50,50))
lapply(a, function(x) {length(x)*2 }
)
df =data.frame(a=1:3, b=4:6, c=7:9)
apply(X=df, MARGIN=1, max)
apply(X=df, max)
?apply
c(1,3,5,7) %in%c(1,5,9)
c(1,5,9) %in%c(1,3,5,7)
df =data.frame(x=15:11,y=21:25)
df
arrange(df, x)
library(dplyr)
arrange(df, x)
mutate(df, z=x+y)
filter(df, x>12, y>22)
df =data.frame(x=4:9, y=c(1,1,1,2,2,3))
df
df %>%group_by(y) %>%summarize(cnt =n(),avg =mean(x))
df %>%group_by(y) %>%arrange(x)
df %>%group_by(y) %>% arrange(x)
df
df =data.frame(x=c(33,10,222,100,66,5), y=c(1,2,1,1,2,2))
df %>%group_by(y) %>% arrange(x)
df
df %>%group_by(y) %>%slice()
df
linkedin <- list(16, 9, 13, 5, 2, 17, 14)
facebook <- list(17, 7, 5, 16, 8, 13, 14)
# Convert linkedin and facebook to a vector: li_vec and fb_vec
li_vec <- as.vector(linkedin)
fb_vec <- as.vector(facebook)
li_vec
as.vector(linkedin)
class(as.vector(linkedin))
class(as.numeric(linkedin))
as.numeric(linkedin)
rep(1, 7, by = 2)
rep(1, 7)
rep(1, 7, by=10)
?rep
seq(1,100)
seq(1,100,2)
seq(1,100,2)??
?
?seq
date()
d <- date()
class(d)
d
date(d)
sys.date()
Sys.Date()
d < -Sys.Date()
d <- Sys.Date()
class(d)
d
hwmjnj=HoltWinters(q.jnj,seasonal='multiplicative')
library()
as.vector(linkedin)
library(FinTS)
data(q.jnj) # load data
class(q.jnj) #
head(q.jnj)
q.jnj
plot(q.jnj)
lines(q.jnj)
lines(q.jnj)
str(q.jnjts)
q.jnjts=as.ts(q.jnj)
class(q.jnjts)
str(q.jnjts)
jnjda=decompose(q.jnjts,type='additive')
#Consider the structure (str) of the object returned by decompose().
str(jnjda)
plot(jnjda$trend)
plot(jnjda$sesonal)
plot(jnjda$random)
plot(jnjda$sesonal)
plot(jnjda$sessonal)
predda=jnjda$trend+jnjda$seasonal
#layout(1:1)
plot(q.jnj,lwd=2)
lines(predda,col='red',lwd=2)
predda=jnjda$trend+jnjda$seasonal+jnjda$random
predda=jnjda$trend+jnjda$seasonal+jnjda$random
#layout(1:1)
plot(q.jnj,lwd=2)
lines(predda,col='red',lwd=2)
layout(1:1)
predda=jnjda$trend+jnjda$seasonal
layout(1:1)
plot(q.jnj,lwd=2)
lines(predda,col='red',lwd=2)
time(jnjda)
time(q.jnjts)
jnjdm=decompose(q.jnjts,type='multiplicative')
# we can plot (same as above) and check root squeare mean error
preddm=jnjdm$trend*jnjdm$seasonal
resid=q.jnjts-preddm
jnjdmresid=window(resid, start=c(1960,3), end=c(1980,2))
rmsedm=sqrt(sum(jnjdmresid^2)/length(jnjdmresid))
rmsedm
jnjd=stl(q.jnj,s.window='periodic')
str(jnjd)
#The object jnjd is a list of 8 items. The one of interest to us is the first item
#This item is a 'matrix' of three columns, 'seasonal','trend','remainder' (or error) component.
#The object jnjd$time.series gives us the three components.
class(jnjd$time.series[,'seasonal'])
plot(jnjd)
pred1=jnjd$time.series[,'seasonal'] + jnjd$time.series[,'trend']
plot(q.jnj,lwd=2)
lines(pred1,col='red',lwd=2)
#rmsed
rmsed=sqrt(sum(jnjd$time.series[,'remainder']^2)/length(jnjd$time.series[,'remainder']))
rmsed
plot(jnjd$time.series[,'remainder'],ylab='Remainder')#plot reminder
# to do multiplicative model
logjnj=log(q.jnj)
plot(logjnj,ylab='log(J&J earnings)')
tsjnjd=stl(logjnj,s.window='periodic')
plot(tsjnjd)
################# REGRESION
#If we want to forecast beyond the last date at which we have data we need to create a forecast of the trend component.
#One approach is to forecast the trend component using a linear regression model
#We want to regress the trend of the log transformed data against time so
#we need to extract the time values of the time series as a separate variable.
tr=tsjnjd$time.series[,'trend']
tim=time(tr)
ti = unclass(tim)
trreg=lm(tr~ti)
plot(tr,lwd=2)
preddata=predict(trreg,data.frame(ti=predtime),se.fit=TRUE)
preddata
predtime=seq(1981,1982, by=.25)
predtime
preddata=predict(trreg,data.frame(ti=predtime),se.fit=TRUE)
preddata
tail(tsjnjd$time.series[,'seasonal'])
season=c(-0.003158759,0.033553454,0.116309601,-0.146704527,-0.003158759)
predvalues=preddata$fit
spredvalues=predvalues+season
spredvalues
# to get 95 confidence intervals
prederror=preddata$se.fit
predupperse=spredvalues+2*prederror
predlwrse=spredvalues-2*prederror
epredvalues=exp(spredvalues)
epredupperse=exp(predupperse)
epredlwrse=exp(predlwrse)
#plot
plot(ti,logjnj,ylim=c(-3,5),xlim=c(1960,1983),type='l')
lines(ti,fitted(trreg),col='red')
points(predtime,predvalues,col='red',pch=19,cex=.8)
lines(predtime,predupperse,col='blue',lwd=2)
lines(predtime,predlwrse,col='blue',lwd=2)
lines(predtime,predlwrse,col='blue',lwd=2)
#plot just the prediction
plot(predtime,spredvalues,ylim=c(2,5),col='red',type='l')
lines(predtime,predupperse,col='blue',lwd=2)
lines(predtime,predlwrse,col='blue',lwd=2)
jtime=time(q.jnj)
jseas=cycle(q.jnj)
jdata=coredata(q.jnj)
jnjreg=lm(jdata~0+jtime+factor(jseas))
summary(jnjreg)
# we understand that the residuals will likely be correlated which technically violates the assumptions
#required for regression (more on that later).
plot(jnjreg)
lines(jtime,jnjhat,col='red')
#hist errors
hist(ejnj)
#AUTOCORRELATION
acf(ejnj)
jnjhat=fitted(jnjreg)
lot(q.jnj,ylim=c(-5,20))
lines(jtime,jnjhat,col='red')
plot(q.jnj,ylim=c(-5,20))
lines(jtime,jnjhat,col='red')
hist(ejnj)
#AUTOCORRELATION
acf(ejnj)
ejnj=resid(jnjreg)
hist(ejnj)
acf(ejnj)
head(wdi.df)
#Describe each variable, including the units of the numeric varables. Describe the meaning of the observations of the dataset.
#Include summaries of individual variables using only the group_by and summarize functions
#from the dplyr library. You must use the pipe operator from the magrittr library.
#Each summary should be interpreted in a way that informs the reader of important
#information about that variable or those variables in the context of the data set.
library(WDI)
library(readr)
library(dplyr)
library(tidyr)
# Read dataframe of wdi.df and drop index column
setwd("C:/Users/carrai1/Desktop/Master/MA402_Data_Science/Assigment_1/")
wdi.df = read_csv("./data/wdi.df.csv")
drops='X1'
wdi.df = wdi.df[ , !(names(wdi.df) %in% drops)]
# check data frame
str(wdi.df)
head(wdi.df)
#check missing values
# check missing values again
wdi.df %>%  group_by(year) %>%  summarize(count=n(), cnt.missing=sum(is.na(value)), pct.missing= 100*cnt.missing/count) %>%
arrange(year) %>%  select(year, pct.missing) %>%   print(n=100)
# same for countries
wdi.df %>%  group_by(country.code) %>%  summarize(count=n(), cnt.missing=sum(is.na(value)), pct.missing= 100*cnt.missing/count) %>%
arrange(country.code) %>%  select(country.code, pct.missing) %>%  arrange(desc(pct.missing)) %>% print(n=250)
summarise(iris, avg = mean(Sepal.Length))
summarise_each(iris, funs(mean))
count(iris, Species, wt = Sepal.Length)
head(wdi.df)
wdi.df %>% group_by(indicator.code) %>% summarise(test=mean(value))
wdi.df %>% group_by(indicator.code) %>% summarise(mean=mean(value), median=(value))
wdi.df %>% group_by(indicator.code) %>% summarise(mean=mean(value), median=median(value))
wdi.df %>% group_by(indicator.code) %>% summarise(mean=mean(value), median=median(value), sd=sd(value), max=max(value),min=min(value))
head(wdi.df)
wdi.df %>% group_by(indicator.name, indicator.code) %>% summarise(mean=mean(value), median=median(value), sd=sd(value), max=max(value),min=min(value))
%>% print(row.names=FALSE)
wdi.df %>% group_by(indicator.name, indicator.code) %>% summarise(mean=mean(value), median=median(value), sd=sd(value), max=max(value),min=min(value))   %>% print(row.names=FALSE)
wdi.df %>% group_by(indicator.name, indicator.code) %>% summarise(mean=mean(value), median=median(value), sd=sd(value), max=max(value),min=min(value))   %>% print(row.names=FALSE)
wdi.df %>% group_by(indicator.name, indicator.code) %>% summarise(mean=mean(value), median=median(value), sd=sd(value), max=max(value),min=min(value)) %>% print(row.names=FALSE)
wdi.df %>% group_by(indicator.name, indicator.code) %>% summarise(mean=mean(value), median=median(value), sd=sd(value), max=max(value),min=min(value))
wdi.df %>% group_by(indicator.name, indicator.code) %>% summarise(mean=mean(value), median=median(value), sd=sd(value), max=max(value),min=min(value)) %>% mutate(value = format(value, scientific = TRUE, digits = 4)
)
wdi.df %>% group_by(indicator.name, indicator.code) %>% summarise(mean=mean(value), median=median(value), sd=sd(value), max=max(value),min=min(value)) %>% mutate(value = format(value, scientific = TRUE, digits = 4))
options(scipen=999)
wdi.df %>% group_by(indicator.name, indicator.code) %>% summarise(mean=mean(value), median=median(value), sd=sd(value), max=max(value),min=min(value))
help(options)
wdi.df %>% group_by(indicator.name, indicator.code) %>% summarise(mean=mean(value), median=median(value), sd=sd(value), max=max(value),min=min(value)) %>% format(round(x, 2), nsmall = 2)
wdi.df %>% group_by(indicator.name, indicator.code) %>% summarise(mean=mean(value), median=median(value), sd=sd(value), max=max(value),min=min(value)) %>% format(round(2), nsmall = 2)
wdi.df %>% group_by(indicator.name, indicator.code) %>% summarise(mean=mean(value), median=median(value), sd=sd(value), max=max(value),min=min(value)) %>% format(round(2), nsmall = 2)
wdi.df %>% group_by(indicator.name, indicator.code) %>% summarise(mean=mean(value), median=median(value), sd=sd(value), max=max(value),min=min(value)) %>% format(round(2), nsmall = 2)
wdi.df %>% group_by(indicator.name, indicator.code) %>% summarise(mean=mean(value), median=median(value), sd=sd(value), max=max(value),min=min(value))
wdi.df %>% group_by(indicator.name, indicator.code) %>% summarise(mean=round(mean(value), 2), median=median(value), sd=sd(value), max=max(value),min=min(value))
wdi.df %>% group_by(indicator.name, indicator.code) %>% summarise(mean=round(mean(value), 2), median=round(median(value), 2), sd=round(sd(value), 2),
max=round(max(value), 2),round(min(value), 2))
wdi.df %>% group_by(indicator.name, indicator.code) %>% summarise(mean=round(mean(value), 2), median=round(median(value), 2), sd=round(sd(value), 2),
wdi.df %>% group_by(year,indicator.code ) %>% summarise(mean=round(mean(value), 2), median=round(median(value), 2), sd=round(sd(value), 2),
wdi.df %>% group_by(year,indicator.code ) %>% summarise(mean=round(mean(value), 2), median=round(median(value), 2), sd=round(sd(value), 2),
max=round(max(value), 2),round(min(value), 2))
wdi.df %>% group_by(year,indicator.code ) %>% summarise(mean=round(mean(value), 2), median=round(median(value), 2), sd=round(sd(value), 2),
max=round(max(value), 2),round(min(value), 2))
wdi.df %>% group_by(year,indicator.code ) %>% summarise(mean=round(mean(value), 2), median=round(median(value), 2), sd=round(sd(value), 2),
max=round(max(value), 2),round(min(value), 2))
wdi.df %>% group_by(year,indicator.code ) %>% summarise(mean=round(mean(value), 2), median=round(median(value), 2), sd=round(sd(value), 2),
max=round(max(value), 2),round(min(value), 2))  %>% print()
head(wdi.df)
wdi.df %>% group_by(country.name) %>% summarise(mean=round(mean(value), 2), median=round(median(value), 2), sd=round(sd(value), 2),
max=round(max(value), 2),round(min(value), 2))
wdi.df %>% group_by(country.name,indicator.code) %>% summarise(mean=round(mean(value), 2), median=round(median(value), 2), sd=round(sd(value), 2),
max=round(max(value), 2),round(min(value), 2))
wdi.df %>% group_by(year,indicator.code ) %>% summarise(mean=round(mean(value), 2), median=round(median(value), 2), sd=round(sd(value), 2),
max=round(max(value), 2),min=round(min(value), 2))  %>% print()
wdi.df %>% group_by(year,indicator.code ) %>% summarise(mean=round(mean(value), 2), median=round(median(value), 2), sd=round(sd(value), 2),
max=round(max(value), 2),min=round(min(value), 2))  %>% print()
wdi.df %>% group_by(year,indicator.code ) %>% summarise(mean=round(mean(value), 2), median=round(median(value), 2), sd=round(sd(value), 2),
max=round(max(value), 2),min=round(min(value), 2))  -> sum.year.code.df
sum.year.code.df
sum.year.code.df$year
unique(sum.year.code.df$year)
for (y in unique(sum.year.code.df$year)){
print(y)
sum.year.code.df %>% filter(year == y) %>% print()
}
wdi.df %>% group_by(country.name,indicator.code) %>% summarise(mean=round(mean(value), 2), median=round(median(value), 2), sd=round(sd(value), 2),
max=round(max(value), 2),min=round(min(value), 2)) -> summary.country.code.df
for (c in unique(summary.country.code.df$country.name)){summary.country.code.df %>% filter(year == y) %>% print()}
wdi.df %>% group_by(country.name,indicator.code) %>% summarise(mean=round(mean(value), 2), median=round(median(value), 2), sd=round(sd(value), 2),
max=round(max(value), 2),min=round(min(value), 2)) -> summary.country.code.df
for (c in unique(summary.country.code.df$country.name)){summary.country.code.df %>% filter(country.name == c) %>% print()}
wdi.df %>% summarise(number_of_unique_years = n_distinct(year))
wdi.df %>% summarise(number_of_unique_ind = n_distinct(indicator.code))
wdi.df %>% summarise(number_of_unique_countries = n_distinct(country.code))
wdi.df %>% summarise(number_of_unique_countries = n_distinct(country.code)) %>% print()
head(wdi.df)
wdi.df %>% summarise_each(mean)
wdi.df %>% summarise_each(funs(mean))
wdi.df %>% summarise_each(funs(unique()))
wdi.df %>% summarise_each(funs(unique))
wdi.df %>% summarise_each(count)
wdi.df %>% summarise_each(func(count))
wdi.df %>% summarise_each(funs(count))
wdi.df %>% count(years)
wdi.df %>% count(year)
wdi.df
wdi.df %>% count(country.code)
wdi.df %>% summarise(number_of_unique_years = n_distinct(year))
wdi.df %>% summarise(number_of_unique_ind = n_distinct(indicator.code))
wdi.df %>% summarise(number_of_unique_countries = n_distinct(country.code)) %>% print()
wdi.df %>% count(years, country.code)
wdi.df %>% count(year, country.code)
wdi.df %>% count(country.code)
