as.numeric(df[1])
as.numeric(df[1])
df$a
mylist = list(a=c(1,2,3),b='hola',c=data.frame(a=c(1,2,3,4,5),b=c(2,3,4,5,6)))
mylist
mylist[1]
mylist[2]
mylist[3]
mylist[[2]]
mylist[2]
type(mylist[2])
class(mylist[2])
class(mylist[[2]])
a = c(4,5,6,7)
a
as.numeric(c(2,"45","1bc","TRUE")) #as.logical, as.character
1:10 < 5
as.numeric(c(TRUE, FALSE))
a[c(2,3)]
a[a]
a[c(TRUE,FALSE,FALSE,FALSE)]
4:1
4:1 * 4:1
quantile(0:20, 0.5)
class(quantile(0:20, 0.5))
str_detect(c("cat","rat","dog"),"at")
library(stringr)
str_detect(c("cat","rat","dog"),"at")
var1 = c('a','b','a','c','d
_)
)
0)))
exit
bye
var1 = c('a','b','a','c','d')
var1 = c('a','b','a','c','d')
fac.var1 =  factor(var1)
var1
fac.var1
summary(fac.var1)
a = cut(1:4, c(0,2,4,8))
a
poker_vector <- c(140, -50, 20, -120, 240)
pv <- c(140, -50, 20, -120, 240)
pv
names(pv)
days_vector <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")
names(pv) <- days_vector
names(pv)
pv
region <- c("US", "non-US")
titles <- c("A New Hope", "The Empire Strikes Back", "Return of the Jedi")
colnames(star_wars_matrix) <- region
urvey_vector <- c("M", "F", "F", "M", "M")
factor_survey_vector <- factor(survey_vector)
# Specify the levels of factor_survey_vector
levels(factor_survey_vector)
cbind("Female", "Male")
c("Female", "Male")
a = cbind("Female", "Male")
a
b = rbind("Female", "Male")
b
m = matrix(1:9, byrow= TRUE, nrow=3)
m
rbind(m, c(7, 7, 7))
cbind(m, c(7, 7, 7))
cbind(7,7,7)
a
a = cbind(7,8,9)
b = rbind(7,8,9)
a
a[2]
a[1,2]
a[2,1]
a[1,1]
b[2,1]
b
vec =c('x','y','z','a','b','c')vec[c(-4, -2)]
vec =c('x','y','z','a','b','c')
vec[c(-4, -2)]
c(-4, -2)
vec[c(-1]
vec[c(-1])
vec[-1)
vec[-1]
vec
vec[-2]
vec[-1]
vec[-3]
vec[-2]
vec[-4]
vec[-3]
vec
vec[-1]
vec[-2]
vec[-2,-3]
vec[c(-2,-3)]
vec =c('x','y','z','a','b','c')
vec =c('x','y','z','a','b','c')
vec =c('x','y','z','a','b','c')
vec[c(6,3,3,1)]
vec =c(-1,2,1)
sum(vec)
sum(vec) != vec
og =c(FALSE, TRUE, FALSE, TRUE
)
og
og[!og]
vec =c(4,2,1,3)
vec[vec]
a =list(5:3,c(2,4),rep(c(1,2),3))
a[2]
a[[2]]
class(a[2])
class(a[[2]])
class(a[[4]])
class(a[4])
a[4]
a
a =list(5:3,c(2,4),rep(c(1,2),3),6)
a[4]
a[[4]]
class(a[[4]])
a =list(0:1, 1:4,c(50,50))
lapply(a,sum)
a =list(0:1, 1:4,c(50,50))
lapply(a, function(x) {length(x)*2 }
)
df =data.frame(a=1:3, b=4:6, c=7:9)
apply(X=df, MARGIN=1, max)
apply(X=df, max)
?apply
c(1,3,5,7) %in%c(1,5,9)
c(1,5,9) %in%c(1,3,5,7)
df =data.frame(x=15:11,y=21:25)
df
arrange(df, x)
library(dplyr)
arrange(df, x)
mutate(df, z=x+y)
filter(df, x>12, y>22)
df =data.frame(x=4:9, y=c(1,1,1,2,2,3))
df
df %>%group_by(y) %>%summarize(cnt =n(),avg =mean(x))
df %>%group_by(y) %>%arrange(x)
df %>%group_by(y) %>% arrange(x)
df
df =data.frame(x=c(33,10,222,100,66,5), y=c(1,2,1,1,2,2))
df %>%group_by(y) %>% arrange(x)
df
df %>%group_by(y) %>%slice()
df
linkedin <- list(16, 9, 13, 5, 2, 17, 14)
facebook <- list(17, 7, 5, 16, 8, 13, 14)
# Convert linkedin and facebook to a vector: li_vec and fb_vec
li_vec <- as.vector(linkedin)
fb_vec <- as.vector(facebook)
li_vec
as.vector(linkedin)
class(as.vector(linkedin))
class(as.numeric(linkedin))
as.numeric(linkedin)
rep(1, 7, by = 2)
rep(1, 7)
rep(1, 7, by=10)
?rep
seq(1,100)
seq(1,100,2)
seq(1,100,2)??
?
?seq
date()
d <- date()
class(d)
d
date(d)
sys.date()
Sys.Date()
d < -Sys.Date()
d <- Sys.Date()
class(d)
d
hwmjnj=HoltWinters(q.jnj,seasonal='multiplicative')
library()
as.vector(linkedin)
library(FinTS)
data(q.jnj) # load data
class(q.jnj) #
head(q.jnj)
q.jnj
plot(q.jnj)
lines(q.jnj)
lines(q.jnj)
str(q.jnjts)
q.jnjts=as.ts(q.jnj)
class(q.jnjts)
str(q.jnjts)
jnjda=decompose(q.jnjts,type='additive')
#Consider the structure (str) of the object returned by decompose().
str(jnjda)
plot(jnjda$trend)
plot(jnjda$sesonal)
plot(jnjda$random)
plot(jnjda$sesonal)
plot(jnjda$sessonal)
predda=jnjda$trend+jnjda$seasonal
#layout(1:1)
plot(q.jnj,lwd=2)
lines(predda,col='red',lwd=2)
predda=jnjda$trend+jnjda$seasonal+jnjda$random
predda=jnjda$trend+jnjda$seasonal+jnjda$random
#layout(1:1)
plot(q.jnj,lwd=2)
lines(predda,col='red',lwd=2)
layout(1:1)
predda=jnjda$trend+jnjda$seasonal
layout(1:1)
plot(q.jnj,lwd=2)
lines(predda,col='red',lwd=2)
time(jnjda)
time(q.jnjts)
jnjdm=decompose(q.jnjts,type='multiplicative')
# we can plot (same as above) and check root squeare mean error
preddm=jnjdm$trend*jnjdm$seasonal
resid=q.jnjts-preddm
jnjdmresid=window(resid, start=c(1960,3), end=c(1980,2))
rmsedm=sqrt(sum(jnjdmresid^2)/length(jnjdmresid))
rmsedm
jnjd=stl(q.jnj,s.window='periodic')
str(jnjd)
#The object jnjd is a list of 8 items. The one of interest to us is the first item
#This item is a 'matrix' of three columns, 'seasonal','trend','remainder' (or error) component.
#The object jnjd$time.series gives us the three components.
class(jnjd$time.series[,'seasonal'])
plot(jnjd)
pred1=jnjd$time.series[,'seasonal'] + jnjd$time.series[,'trend']
plot(q.jnj,lwd=2)
lines(pred1,col='red',lwd=2)
#rmsed
rmsed=sqrt(sum(jnjd$time.series[,'remainder']^2)/length(jnjd$time.series[,'remainder']))
rmsed
plot(jnjd$time.series[,'remainder'],ylab='Remainder')#plot reminder
# to do multiplicative model
logjnj=log(q.jnj)
plot(logjnj,ylab='log(J&J earnings)')
tsjnjd=stl(logjnj,s.window='periodic')
plot(tsjnjd)
################# REGRESION
#If we want to forecast beyond the last date at which we have data we need to create a forecast of the trend component.
#One approach is to forecast the trend component using a linear regression model
#We want to regress the trend of the log transformed data against time so
#we need to extract the time values of the time series as a separate variable.
tr=tsjnjd$time.series[,'trend']
tim=time(tr)
ti = unclass(tim)
trreg=lm(tr~ti)
plot(tr,lwd=2)
preddata=predict(trreg,data.frame(ti=predtime),se.fit=TRUE)
preddata
predtime=seq(1981,1982, by=.25)
predtime
preddata=predict(trreg,data.frame(ti=predtime),se.fit=TRUE)
preddata
tail(tsjnjd$time.series[,'seasonal'])
season=c(-0.003158759,0.033553454,0.116309601,-0.146704527,-0.003158759)
predvalues=preddata$fit
spredvalues=predvalues+season
spredvalues
# to get 95 confidence intervals
prederror=preddata$se.fit
predupperse=spredvalues+2*prederror
predlwrse=spredvalues-2*prederror
epredvalues=exp(spredvalues)
epredupperse=exp(predupperse)
epredlwrse=exp(predlwrse)
#plot
plot(ti,logjnj,ylim=c(-3,5),xlim=c(1960,1983),type='l')
lines(ti,fitted(trreg),col='red')
points(predtime,predvalues,col='red',pch=19,cex=.8)
lines(predtime,predupperse,col='blue',lwd=2)
lines(predtime,predlwrse,col='blue',lwd=2)
lines(predtime,predlwrse,col='blue',lwd=2)
#plot just the prediction
plot(predtime,spredvalues,ylim=c(2,5),col='red',type='l')
lines(predtime,predupperse,col='blue',lwd=2)
lines(predtime,predlwrse,col='blue',lwd=2)
jtime=time(q.jnj)
jseas=cycle(q.jnj)
jdata=coredata(q.jnj)
jnjreg=lm(jdata~0+jtime+factor(jseas))
summary(jnjreg)
# we understand that the residuals will likely be correlated which technically violates the assumptions
#required for regression (more on that later).
plot(jnjreg)
lines(jtime,jnjhat,col='red')
#hist errors
hist(ejnj)
#AUTOCORRELATION
acf(ejnj)
jnjhat=fitted(jnjreg)
lot(q.jnj,ylim=c(-5,20))
lines(jtime,jnjhat,col='red')
plot(q.jnj,ylim=c(-5,20))
lines(jtime,jnjhat,col='red')
hist(ejnj)
#AUTOCORRELATION
acf(ejnj)
ejnj=resid(jnjreg)
hist(ejnj)
acf(ejnj)
# World Development Indicators
#
# This script loads csv downloaded from ://data.worldbank.org/topic
# makes years as a feature and concatenates them together into one data.frame
# then selects a good combination of years/countries without missing values
# Load the WDI, readr and dplyr libraries
library(WDI)
library(readr)
library(dplyr)
library(tidyr)
# Read each one fo the indicators into a data frame from the downloaded CSV files (remove manuall first 3 lines of cvs)
setwd("C:/Users/carrai1/Desktop/Master/MA402_Data_Science/Assigment_1/")
san.df = read_csv("./data/%_access_sanitation_facilities_90_15.csv")
ag.df = read_csv("./data/%_agricultural_land_61_13.csv")
pop0.df = read_csv("./data/%_population_0_14_60_15.csv")
pop15.df = read_csv("./data/%_population_15_64_60_15.csv")
poprur.df= read_csv("./data/%_rural_population_60_15.csv")
popur.df= read_csv("./data/%_urban_population_60_15.csv")
co2.df= read_csv("./data/CO2_emisions_60_11.csv")
kmsqr.df= read_csv("./data/km_square_61_15.csv")
popgrowth.df= read_csv("./data/population_growth_60_15.csv")
poptotal.df= read_csv("./data/population_total_60_15.csv")
elecoutput.df= read_csv("./data/renew_elec_output_90_12.csv")
mort5.df= read_csv("./data/mortality_less5_rate.csv")
energy.df= read_csv("./data/energy_use_kg_oil.csv")
gdp_growth.df= read_csv("./data/GDP_growth_annual%.csv")
gdp.df= read_csv("./data/GDP.csv")
# put all data.frames into a list
all.list <- list(san.df,ag.df,pop0.df,pop15.df,poprur.df,popur.df,co2.df,kmsqr.df,
popgrowth.df,poptotal.df,elecoutput.df,mort5.df,energy.df,
gdp_growth.df,gdp.df)
# chech: loop the list to print first observatinos
for (i in all.list){print(head(i))}
# Join all data.frames into a single data.frame
wdi.df = data.frame()
# loop the list to set year and value as a column and concatenate
for (aux.df in all.list){
# Rename a few variable
aux.df <- rename(aux.df, country.name = `Country Name`, country.code = `Country Code`,indicator.name = `Indicator Name`,indicator.code = `Indicator Code`)
# "Gather" the year variables and values into a pair of variables: `year` and `value`
aux.df <- gather(aux.df, year, value, -country.name, -country.code, -indicator.name, -indicator.code)
#print number of rows to check
print(nrow(aux.df))
#concatenates
wdi.df <- rbind(aux.df,wdi.df)
}
# check structure of final dataframe
str(wdi.df)
# Make the `indicator.code` variable into a factor
wdi.df$indicator.code = factor(wdi.df$indicator.code)
str(wdi.df$indicator.code)
length(unique(wdi.df$indicator.code))
summary(wdi.df$indicator.code)
# Make the `country.code` variable into a factor
wdi.df$country.code = factor(wdi.df$country.code)
str(wdi.df$country.code)
length(unique(wdi.df$country.code))
levels(wdi.df$country.code)
summary(wdi.df$country.code)
# Make the `year` variable into an ordered factor
wdi.df$year = factor(wdi.df$year, ordered=TRUE)
str(wdi.df$year)
levels(wdi.df$year)
summary(wdi.df$year)
# Some final check on our data.frame:
str(wdi.df)
head(wdi.df,4)
sample_n(wdi.df, size=10)
options(dplyr.width = Inf) # forces dplyr to show all columns
slice(wdi.df, 1000:1020)
filter(wdi.df, year==1995)
# Now let's check missing values to select a subset of years (and countries?)
# Display the years sorted by the percent of missing values for all measurements for that year
wdi.df %>%  group_by(year) %>%  summarize(count=n(), cnt.missing=sum(is.na(value)), pct.missing= 100*cnt.missing/count) %>%
arrange(year) %>%  select(year, pct.missing) %>%   print(n=100)
# same for countries
wdi.df %>%  group_by(country.code) %>%  summarize(count=n(), cnt.missing=sum(is.na(value)), pct.missing= 100*cnt.missing/count) %>%
arrange(country.code) %>%  select(country.code, pct.missing) %>%  arrange(desc(pct.missing)) %>% print(n=250)
# We'll also remove column year=x61 and country.code=INX with 100% missing values
wdi.df <- filter(wdi.df, year!="X61")
wdi.df <- filter(wdi.df, country.code!="INX")
# Let's create wdi.dfv2 20 years and 134 countries WITHOUT missing values!!!!!!!!!!!!!!!! :)
wdi.dfv2 <- filter(wdi.df, year>1991& year<2012)
wdi.dfv2 %>%  group_by(country.code) %>%  summarize(count=n(), cnt.missing=sum(is.na(value)), pct.missing= 100*cnt.missing/count) %>%
arrange(country.code) %>%  select(country.code, pct.missing) %>%  arrange(desc(pct.missing)) %>% print(n=270) -> countries.mv
# Keep countries with 0% missing values
country_keep = (filter(countries.mv, pct.missing == 0))$country.code
wdi.dfv2 <- filter(wdi.dfv2, country.code %in% country_keep)
# check missing values again
wdi.dfv2 %>%  group_by(year) %>%  summarize(count=n(), cnt.missing=sum(is.na(value)), pct.missing= 100*cnt.missing/count) %>%
arrange(year) %>%  select(year, pct.missing) %>%   print(n=100)
# same for countries
wdi.dfv2 %>%  group_by(country.code) %>%  summarize(count=n(), cnt.missing=sum(is.na(value)), pct.missing= 100*cnt.missing/count) %>%
arrange(country.code) %>%  select(country.code, pct.missing) %>%  arrange(desc(pct.missing)) %>% print(n=250)
# there are other combinations which have more years and countries but with some missing values.
# Let's save our final data.frame wdi.dfv2 as a csv file
str(wdi.dfv2)
wdi.dfv2$country.code = factor(wdi.dfv2$country.code) #refactor
wdi.dfv2$year = factor(wdi.dfv2$year, ordered=TRUE) #refactor
str(wdi.dfv2)
# World Development Indicators
#
# This script loads csv downloaded from ://data.worldbank.org/topic
# makes years as a feature and concatenates them together into one data.frame
# then selects a good combination of years/countries without missing values
# Load the WDI, readr and dplyr libraries
library(WDI)
library(readr)
library(dplyr)
library(tidyr)
# Read each one fo the indicators into a data frame from the downloaded CSV files (remove manuall first 3 lines of cvs)
setwd("C:/Users/carrai1/Desktop/Master/MA402_Data_Science/Assigment_1/")
san.df = read_csv("./data/%_access_sanitation_facilities_90_15.csv")
ag.df = read_csv("./data/%_agricultural_land_61_13.csv")
pop0.df = read_csv("./data/%_population_0_14_60_15.csv")
pop15.df = read_csv("./data/%_population_15_64_60_15.csv")
poprur.df= read_csv("./data/%_rural_population_60_15.csv")
popur.df= read_csv("./data/%_urban_population_60_15.csv")
co2.df= read_csv("./data/CO2_emisions_60_11.csv")
kmsqr.df= read_csv("./data/km_square_61_15.csv")
popgrowth.df= read_csv("./data/population_growth_60_15.csv")
poptotal.df= read_csv("./data/population_total_60_15.csv")
elecoutput.df= read_csv("./data/renew_elec_output_90_12.csv")
mort5.df= read_csv("./data/mortality_less5_rate.csv")
energy.df= read_csv("./data/energy_use_kg_oil.csv")
gdp_growth.df= read_csv("./data/GDP_growth_annual%.csv")
gdp.df= read_csv("./data/GDP.csv")
# put all data.frames into a list
all.list <- list(san.df,ag.df,pop0.df,pop15.df,poprur.df,popur.df,co2.df,kmsqr.df,
popgrowth.df,poptotal.df,elecoutput.df,mort5.df,energy.df,
gdp_growth.df,gdp.df)
# chech: loop the list to print first observatinos
for (i in all.list){print(head(i))}
# Join all data.frames into a single data.frame
wdi.df = data.frame()
# loop the list to set year and value as a column and concatenate
for (aux.df in all.list){
# Rename a few variable
aux.df <- rename(aux.df, country.name = `Country Name`, country.code = `Country Code`,indicator.name = `Indicator Name`,indicator.code = `Indicator Code`)
# "Gather" the year variables and values into a pair of variables: `year` and `value`
aux.df <- gather(aux.df, year, value, -country.name, -country.code, -indicator.name, -indicator.code)
#print number of rows to check
print(nrow(aux.df))
#concatenates
wdi.df <- rbind(aux.df,wdi.df)
}
# check structure of final dataframe
str(wdi.df)
# Make the `indicator.code` variable into a factor
wdi.df$indicator.code = factor(wdi.df$indicator.code)
str(wdi.df$indicator.code)
length(unique(wdi.df$indicator.code))
summary(wdi.df$indicator.code)
# Make the `country.code` variable into a factor
wdi.df$country.code = factor(wdi.df$country.code)
str(wdi.df$country.code)
length(unique(wdi.df$country.code))
levels(wdi.df$country.code)
summary(wdi.df$country.code)
# Make the `year` variable into an ordered factor
wdi.df$year = factor(wdi.df$year, ordered=TRUE)
str(wdi.df$year)
levels(wdi.df$year)
summary(wdi.df$year)
# Some final check on our data.frame:
str(wdi.df)
head(wdi.df,4)
sample_n(wdi.df, size=10)
options(dplyr.width = Inf) # forces dplyr to show all columns
slice(wdi.df, 1000:1020)
filter(wdi.df, year==1995)
# Now let's check missing values to select a subset of years (and countries?)
# Display the years sorted by the percent of missing values for all measurements for that year
wdi.df %>%  group_by(year) %>%  summarize(count=n(), cnt.missing=sum(is.na(value)), pct.missing= 100*cnt.missing/count) %>%
arrange(year) %>%  select(year, pct.missing) %>%   print(n=100)
# same for countries
wdi.df %>%  group_by(country.code) %>%  summarize(count=n(), cnt.missing=sum(is.na(value)), pct.missing= 100*cnt.missing/count) %>%
arrange(country.code) %>%  select(country.code, pct.missing) %>%  arrange(desc(pct.missing)) %>% print(n=250)
# We'll also remove column year=x61 and country.code=INX with 100% missing values
wdi.df <- filter(wdi.df, year!="X61")
wdi.df <- filter(wdi.df, country.code!="INX")
# Let's create wdi.dfv2 20 years and 134 countries WITHOUT missing values!!!!!!!!!!!!!!!! :)
wdi.dfv2 <- filter(wdi.df, year>1991& year<2012)
wdi.dfv2 %>%  group_by(country.code) %>%  summarize(count=n(), cnt.missing=sum(is.na(value)), pct.missing= 100*cnt.missing/count) %>%
arrange(country.code) %>%  select(country.code, pct.missing) %>%  arrange(desc(pct.missing)) %>% print(n=270) -> countries.mv
# Keep countries with 0% missing values
country_keep = (filter(countries.mv, pct.missing == 0))$country.code
wdi.dfv2 <- filter(wdi.dfv2, country.code %in% country_keep)
# check missing values again
wdi.dfv2 %>%  group_by(year) %>%  summarize(count=n(), cnt.missing=sum(is.na(value)), pct.missing= 100*cnt.missing/count) %>%
arrange(year) %>%  select(year, pct.missing) %>%   print(n=100)
# same for countries
wdi.dfv2 %>%  group_by(country.code) %>%  summarize(count=n(), cnt.missing=sum(is.na(value)), pct.missing= 100*cnt.missing/count) %>%
arrange(country.code) %>%  select(country.code, pct.missing) %>%  arrange(desc(pct.missing)) %>% print(n=250)
# there are other combinations which have more years and countries but with some missing values.
# Let's save our final data.frame wdi.dfv2 as a csv file
str(wdi.dfv2)
wdi.dfv2$country.code = factor(wdi.dfv2$country.code) #refactor
wdi.dfv2$year = factor(wdi.dfv2$year, ordered=TRUE) #refactor
str(wdi.dfv2)
write.csv(file=("./data/wdi.df.csv"), x=wdi.dfv2)
